{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Analysis template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "import scikit_posthocs as sp\n",
    "from fitter import Fitter\n",
    "from brokenaxes import brokenaxes\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import plot_tree\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import kruskal\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy.signal import savgol_filter\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%store -r key_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GUI for data analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find a better way for this!\n",
    "def get_params(bacteria_strain):\n",
    "    with open('key_list.json', 'r') as json_file:\n",
    "        loaded_sample = json.load(json_file)\n",
    "    loaded_specific = loaded_sample[bacteria_strain]\n",
    "    return loaded_specific\n",
    "key_list_1 = get_params('Growth Curve 1_Inocuum and Clostridioformis.xlsx')\n",
    "key_list_2 = get_params('Growth Curve 2.xlsx')\n",
    "key_list_3 = get_params('Growth curve 3.xlsx')\n",
    "key_list_7 = get_params('Growth curve 7.xlsx')\n",
    "key_list_8 = get_params('Growth curve B.animalis.xlsx')\n",
    "key_list_24h = get_params('Fresh vs 24h E.clostridioformis.xlsx')\n",
    "\n",
    "key_list_change_1 = get_params('Media change curve M_intestinale.xlsx')\n",
    "key_list_change_2 = get_params('Media change curve E_clostridioformis.xlsx')\n",
    "key_list_change_3 = get_params('Media change curve 1.xlsx')\n",
    "key_list_change_4 = get_params('Media change curve C.innocuum.xlsx')\n",
    "key_list_change_5 = get_params('Media change curve 2_F plautii 1.xlsx')\n",
    "key_list_change_6 = get_params('Media change curve A.muris.xlsx')\n",
    "key_list_change_7 = get_params('Media change curve B_coccoides.xlsx')\n",
    "key_list_change_8 = get_params('Media change curve A.muciniphila.xlsx')\n",
    "key_list_change_9 = get_params('089a8daf-270b-4cd4-8f3f-a25c28337467')\n",
    "key_list_change_10 = get_params('5adaf57e-1273-4cf2-9caf-b5f697fcdee3')\n",
    "\n",
    "\n",
    "key_list_pellets_1 = get_params(\"75c0c258-1691-4cda-86ac-cbfa606533e4\")\n",
    "key_list_pellets_2 = get_params(\"6a38e0ee-2916-4ce6-9900-d159a21acb42\")\n",
    "key_list_pellets_3 = get_params(\"fcf893a3-bc13-4d99-b641-b63dfc1f4168\")\n",
    "key_list_pellets_4 = get_params(\"81b076b9-3e57-4c5f-bacf-ae9e7c64ed93\")\n",
    "key_list_pellets_5 = get_params(\"b2c77986-4f4c-4d1b-948d-01f7f71446ad\")\n",
    "#second run:\n",
    "k_p_1 = get_params(\"087a504f-d291-4e18-a38c-517c96f1efd7\")\n",
    "k_p_2 = get_params(\"206366d2-dc41-428c-b9ea-3adf9a43cf4c\")\n",
    "k_p_3 = get_params(\"b280b536-d637-486e-82c0-d6c7fad85f94\")\n",
    "k_p_4 = get_params(\"ca400586-af75-4190-a13a-70e17d4218b0\")\n",
    "k_p_5 = get_params(\"9a314afa-6aaa-4065-a82b-ca5dd39518fc\")\n",
    "\n",
    "#fermicutes-run\n",
    "f_p_1 = get_params(\"0f637c82-35f5-4e6b-8328-88977bab148d\") #DSMZ\n",
    "f_p_2 = get_params(\"afa96e91-da0d-4200-8557-172c1b9a48b9\") #Evolved CHOW\n",
    "f_p_3 = get_params(\"5d480bee-7ee4-4bf1-ad43-3fa5c5144683\") #Evolved HFD\n",
    "f_p_4 = get_params(\"83e270ae-461d-4abd-859c-6677030bf49c\") #Non-evolved CHOW\n",
    "f_p_5 = get_params(\"78994102-bc62-4368-8429-3156a11c0cd6\") #Non-evolved HFD\n",
    "\n",
    "#Fast changes:\n",
    "fast_key_mi = get_params(\"cdf011ac-5049-4756-83f0-a52f69ee0b4e\")\n",
    "fast_key_am = get_params(\"21b4a9f8-b851-4e9e-8ab1-e49446f0a489\")\n",
    "fast_key_lr = get_params(\"0521d12f-32c2-4f92-8e56-82cf872da245\")\n",
    "fast_key_fp = get_params(\"934e4d9c-afeb-46ad-80ec-a4cdb594b3f1\")\n",
    "fast_key_ef = get_params(\"bc29489d-5778-405e-9ce3-00535f2391a2\")\n",
    "fast_key_ci = get_params(\"88581f5c-a61f-4f86-9775-0bb13c6e9483\")\n",
    "fast_key_ba = get_params(\"6382f595-12d7-4dde-9112-7822346eba9a\")\n",
    "fast_key_bc = get_params(\"af79de9f-06d8-4f25-8d82-d6830f176080\")\n",
    "fast_key_ec = get_params('907ceb0b-6d2e-48f5-bd78-4278b4e10aff')\n",
    "fast_key_au = get_params('c66443ff-d6ef-4633-b236-53df8abb08bb')\n",
    "\n",
    "GW_1 = pd.read_csv('Datasheet Growth Curve 1_Inocuum and Clostridioformis.xlsx')\n",
    "GW_2 = pd.read_csv('Datasheet Growth curve 2.xlsx')\n",
    "GW_3 = pd.read_csv('Datasheet Growth curve 3.xlsx')\n",
    "GW_7 = pd.read_csv('Datasheet Growth curve 7.xlsx')\n",
    "GW_8 = pd.read_csv('Datasheet Growth curve B.animalis.xlsx')\n",
    "GW_24h = pd.read_csv('Datasheet Fresh vs 24h E.clostridioformis.xlsx')\n",
    "\n",
    "\n",
    "GW_change_1 = pd.read_csv('Datasheet Media change curve M_intestinale.xlsx')\n",
    "GW_change_2 = pd.read_csv('Datasheet Media change curve E_clostridioformis.xlsx')\n",
    "GW_change_3 = pd.read_csv('Datasheet Media change curve 1.xlsx')\n",
    "GW_change_4 = pd.read_csv('Datasheet Media change curve C.innocuum.xlsx')\n",
    "GW_change_5 = pd.read_csv('Datasheet Media change curve 2_F plautii 1.xlsx')\n",
    "GW_change_6 = pd.read_csv('Datasheet Media change curve A.muris.xlsx')\n",
    "GW_change_7 = pd.read_csv('Datasheet Media change curve B_coccoides.xlsx')\n",
    "GW_change_8 = pd.read_csv('Datasheet Media change curve A.muciniphila.xlsx')\n",
    "GW_change_9 = pd.read_csv('Datasheet B.animalis Media change curve B_animalis_L_reuteri.xlsx')\n",
    "GW_change_10 = pd.read_csv('Datasheet L.reuteri Media change curve B_animalis_L_reuteri.xlsx')\n",
    "\n",
    "GW_pellets_1 = pd.read_csv('Datasheet E.faecalis F1 HFD isolated E_faecalis_F1HFD_F3HFD.xlsx')\n",
    "GW_pellets_2 = pd.read_csv('Datasheet E.faecalis F3 HFD isolated E_faecalis_F1HFD_F3HFD.xlsx')\n",
    "GW_pellets_3 = pd.read_csv('Datasheet E.faecalis LTC HFD isolated E_faecalis_LTCHFD_LTCCHOW_F3CHOW.xlsx')\n",
    "GW_pellets_4 = pd.read_csv('Datasheet E.faecalis LTC CHOW isolated E_faecalis_LTCHFD_LTCCHOW_F3CHOW.xlsx')\n",
    "GW_pellets_5 = pd.read_csv('Datasheet E.faecalis F3 CHOW isolated E_faecalis_LTCHFD_LTCCHOW_F3CHOW.xlsx')\n",
    "\n",
    "#second run\n",
    "g_p_1 = pd.read_csv('Datasheet E.faecalis F1 HFD Isolated E_faecalis_F1HFD_F3_HFD_F3_CHW.xlsx')\n",
    "g_p_2 = pd.read_csv('Datasheet E.faecalis F3 HFD Isolated E_faecalis_F1HFD_F3_HFD_F3_CHW.xlsx')\n",
    "g_p_3 = pd.read_csv('Datasheet E.faecalis F3 CHOW Isolated E_faecalis_F1HFD_F3_HFD_F3_CHW.xlsx')\n",
    "g_p_4 = pd.read_csv('Datasheet E.faecalis LTC HFD Isolated E_faecalis_F1HFD_F3_HFD_F3_CHW.xlsx')\n",
    "g_p_5 = pd.read_csv('Datasheet E.faecalis LTC CHOW Isolated E_faecalis_F1HFD_F3_HFD_F3_CHW.xlsx')\n",
    "\n",
    "#Fermicutes run\n",
    "f_1 = pd.read_csv('Datasheet E.faecalis DSMZ Isolated E_faecalis_Firmicutes.xlsx')\n",
    "f_2 = pd.read_csv('Datasheet E.faecalis Evolved CHOW Isolated E_faecalis_Firmicutes.xlsx')\n",
    "f_3 = pd.read_csv('Datasheet E.faecalis Evolved HFD Isolated E_faecalis_Firmicutes.xlsx')\n",
    "f_4 = pd.read_csv('Datasheet E.faecalis non-evolved CHOW Isolated E_faecalis_Firmicutes.xlsx')\n",
    "f_5 = pd.read_csv('Datasheet E.faecalis Non-evolved HFD Isolated E_faecalis_Firmicutes.xlsx')\n",
    "\n",
    "#Fast changes:\n",
    "fast_mi = pd.read_csv('Datasheet M.intestinale Fast media change_M_intestinale_A_muris.xlsx')\n",
    "fast_am = pd.read_csv('Datasheet A.muris Fast media change_M_intestinale_A_muris.xlsx')\n",
    "fast_lr = pd.read_csv('Datasheet L.reuteri Fast media change_L_retueri_F_plautii.xlsx')\n",
    "fast_fp = pd.read_csv('Datasheet F.plautii Fast media change_L_retueri_F_plautii.xlsx')\n",
    "fast_ef = pd.read_csv('Datasheet E.faecalis Fast media change_E_faecalis_C_innocuum.xlsx')\n",
    "fast_ci = pd.read_csv('Datasheet C.innocuum Fast media change_E_faecalis_C_innocuum.xlsx')\n",
    "fast_ba = pd.read_csv('Datasheet B.animalis Fast media change_B_animalis_B_coccoisdes.xlsx')\n",
    "fast_bc = pd.read_csv('Datasheet B.coccoides Fast media change_B_animalis_B_coccoisdes.xlsx')\n",
    "fast_ec = pd.read_csv('Datasheet E.clostridioformis Fast media change_E_clostridioformis_A_muciniphila.xlsx')\n",
    "fast_au = pd.read_csv('Datasheet A.muciniphila Fast media change_E_clostridioformis_A_muciniphila.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_dataframe_calculation(para_dict, df, inoc_cond):\n",
    "    well_params = {}\n",
    "    for param_set in para_dict:\n",
    "        for well in param_set['Wells']:\n",
    "            if inoc_cond == False:\n",
    "                well_params[well] = {'Strain': param_set['Strain'], 'Status': param_set['Status'], 'Medium': param_set['Medium']}\n",
    "            else:\n",
    "                well_params[well] = {'Strain': param_set['Strain'], 'Status': param_set['Status'], 'Medium': param_set['Medium'], 'Inoculation conditions': param_set['Inoculation']}\n",
    "    df['Status'] = df['Wells'].map(lambda x: well_params[x]['Status'])\n",
    "    df['Medium composition'] = df['Wells'].map(lambda x: well_params[x]['Medium'])\n",
    "    if inoc_cond == True:\n",
    "        df['Inoculation'] = df['Wells'].map(lambda x: well_params[x]['Inoculation conditions'])\n",
    "    df.rename(columns={'Bacterial_strain': 'Bacterial strain'}, inplace=True)\n",
    "    return df\n",
    "\n",
    "G1 = normal_dataframe_calculation(key_list_1, GW_1, True)\n",
    "G2 = normal_dataframe_calculation(key_list_2, GW_2, True)\n",
    "G3 = normal_dataframe_calculation(key_list_3, GW_3, True)\n",
    "G7 = normal_dataframe_calculation(key_list_7, GW_7, True)\n",
    "G8 = normal_dataframe_calculation(key_list_8, GW_8, True)\n",
    "G24 = normal_dataframe_calculation(key_list_24h, GW_24h, True)\n",
    "\n",
    "Gc1 = normal_dataframe_calculation(key_list_change_1, GW_change_1, True)\n",
    "Gc2 = normal_dataframe_calculation(key_list_change_2, GW_change_2, True)\n",
    "Gc3 = normal_dataframe_calculation(key_list_change_3, GW_change_3, True)\n",
    "Gc4 = normal_dataframe_calculation(key_list_change_4, GW_change_4, True)\n",
    "Gc5 = normal_dataframe_calculation(key_list_change_5, GW_change_5, True)\n",
    "Gc6 = normal_dataframe_calculation(key_list_change_6, GW_change_6, True)\n",
    "Gc7 = normal_dataframe_calculation(key_list_change_7, GW_change_7, True)\n",
    "Gc8 = normal_dataframe_calculation(key_list_change_8, GW_change_8, True)\n",
    "Gc9 = normal_dataframe_calculation(key_list_change_9, GW_change_9, True)\n",
    "Gc10 = normal_dataframe_calculation(key_list_change_10, GW_change_10, True)\n",
    "\n",
    "#pellets 1\n",
    "Gp1 = normal_dataframe_calculation(key_list_pellets_1, GW_pellets_1, False)\n",
    "Gp2 = normal_dataframe_calculation(key_list_pellets_2, GW_pellets_2, False)\n",
    "Gp3 = normal_dataframe_calculation(key_list_pellets_3, GW_pellets_3, False)\n",
    "Gp4 = normal_dataframe_calculation(key_list_pellets_4, GW_pellets_4, False)\n",
    "Gp5 = normal_dataframe_calculation(key_list_pellets_5, GW_pellets_5, False)\n",
    "\n",
    "#pellets 2\n",
    "fp1 = normal_dataframe_calculation(f_p_1, f_1, False)\n",
    "fp2= normal_dataframe_calculation(f_p_2, f_2, False)\n",
    "fp3 = normal_dataframe_calculation(f_p_3, f_3, False)\n",
    "fp4 = normal_dataframe_calculation(f_p_4, f_4, False)\n",
    "fp5 = normal_dataframe_calculation(f_p_5, f_5, False)\n",
    "\n",
    "#fast changes\n",
    "f_mi = normal_dataframe_calculation(fast_key_mi, fast_mi, True)\n",
    "f_am = normal_dataframe_calculation(fast_key_am, fast_am, True)\n",
    "f_lr = normal_dataframe_calculation(fast_key_lr, fast_lr, True)\n",
    "f_fp = normal_dataframe_calculation(fast_key_fp, fast_fp, True)\n",
    "f_ef = normal_dataframe_calculation(fast_key_ef, fast_ef, True)\n",
    "f_ci = normal_dataframe_calculation(fast_key_ci, fast_ci, True)\n",
    "f_ba = normal_dataframe_calculation(fast_key_ba, fast_ba, True)\n",
    "f_bc = normal_dataframe_calculation(fast_key_bc, fast_bc, True)\n",
    "f_ec = normal_dataframe_calculation(fast_key_ec, fast_ec, True)\n",
    "f_au = normal_dataframe_calculation(fast_key_au, fast_au, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_dataframe_calculation(df, num_cycles, name_list, inoc):\n",
    "    global medium_list\n",
    "    global status_list\n",
    "    dict_frame = {}\n",
    "    dict_time = {}\n",
    "    df_mean = pd.DataFrame()\n",
    "    medium = []\n",
    "    status = []\n",
    "    strain = []\n",
    "    wells = []\n",
    "    inoculation = []\n",
    "    subwells = []\n",
    "    mean_values = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        key = row['Wells']\n",
    "        value = row['Extinction OD620nm']\n",
    "        time = row['Time in h']\n",
    "        if key in dict_frame:\n",
    "            dict_frame[key].append(value)\n",
    "            dict_time[key].append(time)\n",
    "        else:\n",
    "            dict_frame[key] = [value]\n",
    "            dict_time[key] = [time]\n",
    "    #Due to low variability, just one was taken as average!\n",
    "    average_time = []\n",
    "    for well, time in dict_time.items():\n",
    "        average_time = time\n",
    "    for items in name_list:\n",
    "            for key, value in items.items():\n",
    "                if key == 'Strain':\n",
    "                    strain.append(value)\n",
    "                elif key == 'Status':\n",
    "                    status.append(value)\n",
    "                elif key == 'Medium':\n",
    "                    medium.append(value)\n",
    "                elif key == 'Wells':\n",
    "                    wells.extend(value)\n",
    "                if inoc == True:\n",
    "                    if key == 'Inoculation':\n",
    "                        inoculation.extend([value])\n",
    "    medium_list = medium\n",
    "    status_list = status\n",
    "    subwells = [wells[i:i+int((len(wells) / len(medium)))] for i in range(0, len(wells), int((len(wells) / len(medium))))]\n",
    "    strain = [item for item in strain for _ in range(num_cycles)]\n",
    "    average_time = average_time * len(medium)\n",
    "    medium = [item for item in medium for _ in range(num_cycles)]\n",
    "    status = [item for item in status for _ in range(num_cycles)]\n",
    "    if inoc == True:\n",
    "        inoculation = [item for item in inoculation for _ in range(int(len(strain) / len(inoculation)))]\n",
    "    for items in subwells:\n",
    "        for i in range(num_cycles):\n",
    "            extinction_values = []\n",
    "            for well in items:\n",
    "                extinction_values.append(dict_frame[well][i])    \n",
    "            mean_values.append(statistics.mean(extinction_values))\n",
    "    if inoc == False:\n",
    "        df_extinction = pd.DataFrame({'Bacterial strain':strain, 'Extinction OD620nm': mean_values, 'Time in h': average_time, 'Medium composition': medium, 'Status': status})\n",
    "    else:\n",
    "        df_extinction = pd.DataFrame({'Bacterial strain':strain, 'Extinction OD620nm': mean_values, 'Time in h': average_time, 'Medium composition': medium, 'Status': status, 'Inoculation': inoculation})\n",
    "    df_mean = pd.concat([df_mean, df_extinction])   \n",
    "        \n",
    "    return df_mean\n",
    "\n",
    "            \n",
    "deff = mean_dataframe_calculation(GW_1, 144, key_list_1, True)\n",
    "deff_2 = mean_dataframe_calculation(GW_2, 144, key_list_2, True)\n",
    "deff_3 = mean_dataframe_calculation(GW_3, 144, key_list_3, True)\n",
    "deff_7 = mean_dataframe_calculation(GW_7, 144, key_list_7, True)\n",
    "deff_8 = mean_dataframe_calculation(GW_8, 288, key_list_8, True)\n",
    "deff_24h = mean_dataframe_calculation(GW_24h, 144, key_list_24h, True)\n",
    "\n",
    "deff_change_1 = mean_dataframe_calculation(GW_change_1, 144, key_list_change_1, True)\n",
    "deff_change_2 = mean_dataframe_calculation(GW_change_2, 144, key_list_change_2, True)\n",
    "deff_cahnge_3 = mean_dataframe_calculation(GW_change_3, 144, key_list_change_3, True)\n",
    "deff_cahnge_4 = mean_dataframe_calculation(GW_change_4, 144, key_list_change_4, True)\n",
    "deff_cahnge_5 = mean_dataframe_calculation(GW_change_5, 144, key_list_change_5, True)\n",
    "deff_change_6 = mean_dataframe_calculation(GW_change_6, 144, key_list_change_6, True)\n",
    "deff_change_7 = mean_dataframe_calculation(GW_change_7, 144, key_list_change_7, True)\n",
    "deff_change_8 = mean_dataframe_calculation(GW_change_8, 144, key_list_change_8, True)\n",
    "deff_change_9 = mean_dataframe_calculation(GW_change_9, 144, key_list_change_9, True)\n",
    "deff_change_10 = mean_dataframe_calculation(GW_change_10, 144, key_list_change_10, True)\n",
    "\n",
    "pellets_1 = mean_dataframe_calculation(GW_pellets_1, 144, key_list_pellets_1, False)\n",
    "pellets_2 = mean_dataframe_calculation(GW_pellets_2, 144, key_list_pellets_2, False)\n",
    "pellets_3 = mean_dataframe_calculation(GW_pellets_3, 144, key_list_pellets_3, False)\n",
    "pellets_4 = mean_dataframe_calculation(GW_pellets_4, 144, key_list_pellets_4, False)\n",
    "pellets_5 = mean_dataframe_calculation(GW_pellets_5, 144, key_list_pellets_5, False)\n",
    "\n",
    "#second run\n",
    "p_1 = mean_dataframe_calculation(g_p_1, 144, k_p_1, False)\n",
    "p_2 = mean_dataframe_calculation(g_p_2, 144, k_p_2, False)\n",
    "p_3 = mean_dataframe_calculation(g_p_3, 144, k_p_3, False)\n",
    "p_4 = mean_dataframe_calculation(g_p_4, 144, k_p_4, False)\n",
    "p_5 = mean_dataframe_calculation(g_p_5, 144, k_p_5, False)\n",
    "\n",
    "#Firmicutes\n",
    "fm1 = mean_dataframe_calculation(f_1, 144, f_p_1, False)\n",
    "fm2 = mean_dataframe_calculation(f_2, 144, f_p_2, False)\n",
    "fm3 = mean_dataframe_calculation(f_3, 144, f_p_3, False)\n",
    "fm4 = mean_dataframe_calculation(f_4, 144, f_p_4, False)\n",
    "fm5 = mean_dataframe_calculation(f_5, 144, f_p_5, False)\n",
    "#Fast changes\n",
    "fast_change_mi = mean_dataframe_calculation(fast_mi, 144, fast_key_mi, True)\n",
    "fast_change_am = mean_dataframe_calculation(fast_am, 144, fast_key_am, True)\n",
    "fast_change_lr = mean_dataframe_calculation(fast_lr, 144, fast_key_lr, True)\n",
    "fast_change_fp = mean_dataframe_calculation(fast_fp, 144, fast_key_fp, True)\n",
    "fast_change_ef = mean_dataframe_calculation(fast_ef, 144, fast_key_ef, True)\n",
    "fast_change_ci = mean_dataframe_calculation(fast_ci, 144, fast_key_ci, True)\n",
    "fast_change_ba = mean_dataframe_calculation(fast_ba, 144, fast_key_ba, True)\n",
    "fast_change_bc = mean_dataframe_calculation(fast_bc, 144, fast_key_bc, True)\n",
    "fast_change_ec = mean_dataframe_calculation(fast_ec, 144, fast_key_ec, True)\n",
    "fast_change_au = mean_dataframe_calculation(fast_au, 144, fast_key_au, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_df = pd.DataFrame(columns= ('strain', 'slope', 'Media composition', 'Status'))\n",
    "def find_max_positive_slope_derivative(df, slope_df, mean, inoc):\n",
    "    key_map = {\n",
    "        (True, True): ['Medium composition', 'Status', 'Inoculation'],\n",
    "        (True, False): ['Medium composition', 'Status'],\n",
    "        (False, False): ['Medium composition', 'Status', 'Wells'],\n",
    "        (False, True): ['Medium composition', 'Status', 'Wells', 'Inoculation']\n",
    "    }\n",
    "    value_list = []\n",
    "    for datasets in df:\n",
    "        grouped_keys = key_map[(mean, inoc)]\n",
    "        grouped = datasets.groupby(grouped_keys, sort = False)\n",
    "        for name, group in grouped:\n",
    "            bac_name = group['Bacterial strain'].head(1).values[0]\n",
    "            x_data = group['Time in h'].values\n",
    "            y_data = group['Extinction OD620nm'].values\n",
    "            \n",
    "            # Calculate derivative\n",
    "            dy_dx = np.gradient(y_data, x_data)\n",
    "            max_positive_slope_index = np.argmax(dy_dx)  # Find index of maximum positive slope\n",
    "        \n",
    "            #sns.lineplot(x=x_data, y=y_data)\n",
    "            #plt.axvline(x=x_data[max_positive_slope_index], color='r', linestyle='--')\n",
    "            #plt.show()\n",
    "            item_dict = {\n",
    "                'strain': group['Bacterial strain'].head(1).values[0],\n",
    "                'slope': float(dy_dx[max_positive_slope_index]),\n",
    "                'Media composition': group['Medium composition'].head(1).values[0],\n",
    "                'Status': group['Status'].head(1).values[0]\n",
    "            }\n",
    "            \n",
    "            if mean == False:\n",
    "                item_dict['Well'] = group['Wells'].head(1).values[0]\n",
    "            if inoc == True:\n",
    "                item_dict['Inoculation'] = group['Inoculation'].head(1).values[0]\n",
    "            \n",
    "            value_list.append(item_dict)\n",
    "            df_temporary = pd.DataFrame(value_list)\n",
    "            concat_df = pd.concat([slope_df, df_temporary])\n",
    "    return concat_df\n",
    "\n",
    "df = find_max_positive_slope_derivative([deff, deff_2, deff_3, deff_7, deff_8], slope_df, True, True)\n",
    "df_change = find_max_positive_slope_derivative([deff_change_1, deff_change_2, deff_cahnge_3, deff_cahnge_4, deff_cahnge_5, deff_change_6, deff_change_7, deff_change_8, deff_change_9, deff_change_10], slope_df, True, True)\n",
    "df_non_mean = find_max_positive_slope_derivative([G1,G2,G3,G7,G8], slope_df, False, False)\n",
    "df_change_non_mean = find_max_positive_slope_derivative([Gc1,Gc2,Gc3,Gc4,Gc5,Gc6,Gc7,Gc8,Gc9, Gc10], slope_df, False, False)\n",
    "\n",
    "df_24h = find_max_positive_slope_derivative([deff_24h], slope_df, True, True)\n",
    "df_24h_non_mean = find_max_positive_slope_derivative([G24], slope_df, False, True)\n",
    "\n",
    "df_pellets = find_max_positive_slope_derivative([pellets_1, pellets_2, pellets_3, pellets_4, pellets_5], slope_df, True, False)\n",
    "df_p = find_max_positive_slope_derivative([p_1, p_2, p_3, p_4, p_5],slope_df, True, False )\n",
    "\n",
    "firmi_df = find_max_positive_slope_derivative([fm1, fm2, fm3, fm4, fm5], slope_df, True, False)\n",
    "\n",
    "df_fast = find_max_positive_slope_derivative([fast_change_mi, fast_change_am, fast_change_lr, fast_change_fp, fast_change_ef, fast_change_ci, fast_change_ba, fast_change_bc, fast_change_ec, fast_change_au], slope_df, True, True)\n",
    "df_fast_non_mean = find_max_positive_slope_derivative([f_mi, f_am, f_lr, f_fp, f_ef, f_ci, f_ba, f_bc, f_ec, f_au], slope_df, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding max OD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_OD(df, width, df_results, num_cycles, mean, inoc):\n",
    "    max_dict = {}\n",
    "    key_map = {\n",
    "        (True, True): ['Medium composition', 'Status', 'Inoculation'],\n",
    "        (True, False): ['Medium composition', 'Status'],\n",
    "        (False, False): ['Medium composition', 'Status', 'Wells'],\n",
    "        (False, True): ['Medium composition', 'Status', 'Wells', 'Inoculation']\n",
    "    }\n",
    "    value_list = []\n",
    "    for datasets in df:\n",
    "        grouped_keys = key_map[(mean, inoc)]\n",
    "        grouped = datasets.groupby(grouped_keys, sort = False)\n",
    "        for name, group in grouped:\n",
    "            strain_name = group['Bacterial strain'].iloc[0]\n",
    "            media_comp = group['Medium composition'].iloc[0]\n",
    "            if inoc == True:\n",
    "                inoculation = group['Inoculation'].iloc[0]\n",
    "            if mean == False:\n",
    "                well = group['Wells'].iloc[0]\n",
    "            status = group['Status'].iloc[0]\n",
    "            values = []\n",
    "            list_v = []\n",
    "            max_value = 0\n",
    "            counter = 0\n",
    "            values_np = (group['Extinction OD620nm']).values\n",
    "            values = values_np.tolist()\n",
    "            for i in range(num_cycles):\n",
    "                if values[i] > max_value:\n",
    "                    max_value = values[i]\n",
    "                    list_v.append(max_value)\n",
    "                    counter = 0\n",
    "                elif counter < width:\n",
    "                    counter += 1\n",
    "                else:\n",
    "                    break\n",
    "            if mean == True and inoc == True:\n",
    "                key = f\"{strain_name}_{media_comp}_{status}_{inoculation}\"\n",
    "            elif mean == True and inoc == False:\n",
    "                key = f\"{strain_name}_{media_comp}_{status}\"\n",
    "            elif mean == False and inoc == True:\n",
    "                key = f\"{strain_name}_{media_comp}_{status}_{well}_{inoculation}\"\n",
    "            else:\n",
    "                key = f\"{strain_name}_{media_comp}_{status}_{well}\"\n",
    "            max_dict[key] = list_v[-1] if list_v else 0\n",
    "    for key, value in max_dict.items():\n",
    "        value_list.append(value)\n",
    "    df_results['Max growth'] = value_list\n",
    "    return df_results\n",
    "\n",
    "    \n",
    "a = max_OD([deff, deff_2, deff_3, deff_7, deff_8], 100, df, 144, True, True)\n",
    "b = max_OD([deff_change_1, deff_change_2, deff_cahnge_3, deff_cahnge_4, deff_cahnge_5, deff_change_6, deff_change_7, deff_change_8, deff_change_9, deff_change_10], 100, df_change, 144, True, True)\n",
    "c = max_OD([G1,G2,G3,G7,G8], 100, df_non_mean, 144, False, False)\n",
    "d = max_OD([Gc1,Gc2,Gc3,Gc4,Gc5,Gc6,Gc7,Gc8, Gc9, Gc10], 100, df_change_non_mean, 144, False, False)\n",
    "e = max_OD([deff_24h], 100, df_24h, 144, True, True)\n",
    "f = max_OD([G24], 100, df_24h_non_mean, 144, False, True)\n",
    "g = max_OD([pellets_1, pellets_2, pellets_3, pellets_4, pellets_5], 100, df_pellets, 144, True, False)\n",
    "h = max_OD([fast_change_mi, fast_change_am, fast_change_lr, fast_change_fp, fast_change_ef, fast_change_ci, fast_change_ba, fast_change_bc, fast_change_ec, fast_change_au], 100, df_fast, 144, True, True)\n",
    "x = max_OD([p_1, p_2, p_3, p_4, p_5], 100, df_p, 144, True, False)\n",
    "y = max_OD([f_mi, f_am, f_lr, f_fp, f_ef, f_ci, f_ba, f_bc, f_ec, f_au], 100, df_fast_non_mean, 144, False, True)\n",
    "z = max_OD([fm1, fm2, fm3, fm4, fm5], 100, firmi_df, 144, True, False)\n",
    "#Good but first maximum should be stated, not from the whole curve!!\n",
    "#Optimize for lower OD's and test for correct values!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#think about this, maybe not 50% but rather a certain defined limit. Like this, strains with big max growth are punished score wise\n",
    "\n",
    "from bisect import bisect_left\n",
    "\n",
    "def fifty_max(df, df_summary):\n",
    "    dict = {}\n",
    "    value_list = []\n",
    "    for datasets in df:\n",
    "        grouped = datasets.groupby(['Bacterial strain', 'Medium composition', 'Status'], sort = False)\n",
    "        for name, group in grouped:\n",
    "            strain_name = group['Bacterial strain'].iloc[0]\n",
    "            media_comp = group['Medium composition'].iloc[0]\n",
    "            status = group['Status'].iloc[0]\n",
    "            if (strain_name in df_summary['strain'].values):\n",
    "                filtered_data = df_summary.loc[(df_summary['strain'] == strain_name) & (df_summary['Media composition'] == media_comp) & (df_summary['Status'] == status)]\n",
    "                max_OD = filtered_data['Max growth']\n",
    "                extinction_values = group['Extinction OD620nm'].values\n",
    "                time_values = group['Time in h'].values\n",
    "                pos_fifty = bisect_left(extinction_values, (max_OD.iloc[0] / 2))\n",
    "                if pos_fifty >= len(time_values):\n",
    "                    time_index = time_values[-1]\n",
    "                else:\n",
    "                    time_index = time_values[pos_fifty]\n",
    "                max_key = f\"{strain_name}_{media_comp}_{status}\"\n",
    "                dict[max_key] = time_index\n",
    "            else:\n",
    "                continue\n",
    "    for keys, values in dict.items():\n",
    "        value_list.append(values)\n",
    "    df_summary['Time for 1/2 max growth'] = value_list\n",
    "    return df_summary\n",
    "\n",
    "fifty_max([pellets_1, pellets_2, pellets_3, pellets_4, pellets_5], df_pellets)\n",
    "fifty_max([deff, deff_2, deff_3, deff_7, deff_8], df)\n",
    "fifty_max([deff_change_1, deff_change_2, deff_cahnge_3, deff_cahnge_4, deff_cahnge_5, deff_change_6, deff_change_7, deff_change_8, deff_change_9, deff_change_10], df_change)\n",
    "fifty_max([fast_change_mi, fast_change_am, fast_change_lr, fast_change_fp, fast_change_ef, fast_change_ci, fast_change_ba, fast_change_bc, fast_change_ec, fast_change_au], df_fast)\n",
    "fifty_max([p_1, p_2, p_3, p_4, p_5], df_p)\n",
    "#fifty_max([f_mi, f_am, f_lr, f_fp, f_ef, f_ci, f_ba, f_bc, f_ec, f_au], df_fast_non_mean)\n",
    "#fifty_max([G1,G2,G3,G7,G8], df_non_mean)\n",
    "#fifty_max([Gc1,Gc2,Gc3,Gc4,Gc5,Gc6,Gc7,Gc8,Gc9,Gc10], df_change_non_mean)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC calculation:\n",
    "def auc_calc(df, df_results, mean, inoc):\n",
    "    max_dict = {}\n",
    "    key_map = {\n",
    "        (True, True): ['Medium composition', 'Status', 'Inoculation'],\n",
    "        (True, False): ['Medium composition', 'Status'],\n",
    "        (False, False): ['Medium composition', 'Status', 'Wells'],\n",
    "        (False, True): ['Medium composition', 'Status', 'Wells', 'Inoculation']\n",
    "    }\n",
    "    value_list = []\n",
    "    for datasets in df:\n",
    "        grouped_keys = key_map[(mean, inoc)]\n",
    "        grouped = datasets.groupby(grouped_keys, sort = False)\n",
    "        for name, group in grouped:\n",
    "            strain_name = group['Bacterial strain'].iloc[0]\n",
    "            media_comp = group['Medium composition'].iloc[0]\n",
    "            if inoc == True:\n",
    "                inoculation = group['Inoculation'].iloc[0]\n",
    "            status = group['Status'].iloc[0]\n",
    "            if mean == False:\n",
    "                well = group['Wells'].iloc[0]\n",
    "            x_data = group['Time in h'].values\n",
    "            y_data = group['Extinction OD620nm'].values\n",
    "            sorted_indices = np.argsort(x_data)\n",
    "            x_data_sorted = x_data[sorted_indices]\n",
    "            y_data_sorted = y_data[sorted_indices]\n",
    "            X = np.array(x_data_sorted).reshape(-1, 1)\n",
    "            Y = np.array(y_data_sorted)\n",
    "            if mean == True and inoc == True:\n",
    "                key = f\"{strain_name}_{media_comp}_{status}_{inoculation}\"\n",
    "            elif mean == True and inoc == False:\n",
    "                key = f\"{strain_name}_{media_comp}_{status}\"\n",
    "            elif mean == False and inoc == True:\n",
    "                key = f\"{strain_name}_{media_comp}_{status}_{well}_{inoculation}\"\n",
    "            else:\n",
    "                key = f\"{strain_name}_{media_comp}_{status}_{well}\"\n",
    "            max_dict[key] = auc(X,Y)\n",
    "    for strain, value in max_dict.items():\n",
    "        value_list.append(value)\n",
    "    df_results['AUC (Biomass)'] = value_list\n",
    "    return df_results\n",
    "\n",
    "auc_calc([deff, deff_2, deff_3, deff_7, deff_8], df, True, True)\n",
    "auc_calc([deff_change_1, deff_change_2, deff_cahnge_3, deff_cahnge_4, deff_cahnge_5, deff_change_6, deff_change_7, deff_change_8, deff_change_9, deff_change_10], df_change, True, True)\n",
    "auc_calc([G1,G2,G3,G7,G8], df_non_mean, False, False)\n",
    "auc_calc([Gc1,Gc2,Gc3,Gc4,Gc5,Gc6,Gc7,Gc8,Gc9,Gc10], df_change_non_mean, False, False)\n",
    "auc_calc([deff_24h], df_24h, True, True)\n",
    "auc_calc([G24], df_24h_non_mean, False, True)\n",
    "auc_calc([pellets_1, pellets_2, pellets_3, pellets_4, pellets_5], df_pellets, True, False)\n",
    "auc_calc([p_1, p_2, p_3, p_4, p_5], df_p, True, False)\n",
    "auc_calc([fast_change_mi, fast_change_am, fast_change_lr, fast_change_fp, fast_change_ef, fast_change_ci, fast_change_ba, fast_change_bc, fast_change_ec, fast_change_au], df_fast, True, True)\n",
    "auc_calc([f_mi, f_am, f_lr, f_fp, f_ef, f_ci, f_ba, f_bc, f_ec, f_au], df_fast_non_mean, False, True)\n",
    "auc_calc([fm1, fm2, fm3, fm4, fm5], firmi_df, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doubling_time(df_results):\n",
    "    double_t = []\n",
    "    grouped = df_results.groupby('slope')\n",
    "    for item in df_results['slope']:\n",
    "        if item == 0:\n",
    "            value = np.inf  # Handle division by zero\n",
    "        else:\n",
    "            value = np.log(2) / item\n",
    "        \n",
    "        if value >= 50 or value == np.inf or value <= 0:  # Handle cases for inf, negative, or too large values\n",
    "            value = 50\n",
    "        double_t.append(value)\n",
    "    \n",
    "        \n",
    "    df_results['Doubling time'] = double_t\n",
    "    return df_results\n",
    "\n",
    "doubling_time(df)\n",
    "doubling_time(df_change)\n",
    "doubling_time(df_non_mean)\n",
    "doubling_time(df_change_non_mean)\n",
    "doubling_time(df_24h)\n",
    "doubling_time(df_24h_non_mean)\n",
    "doubling_time(df_pellets)\n",
    "doubling_time(df_fast)\n",
    "doubling_time(df_p)\n",
    "doubling_time(df_fast_non_mean)\n",
    "doubling_time(firmi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onset_derivatives(df, window, threshold, df_results, mean, inoc):\n",
    "    max_dict = {}\n",
    "    key_map = {\n",
    "        (True, True): ['Medium composition', 'Status', 'Inoculation'],\n",
    "        (True, False): ['Medium composition', 'Status'],\n",
    "        (False, False): ['Medium composition', 'Status', 'Wells'],\n",
    "        (False, True): ['Medium composition', 'Status', 'Wells', 'Inoculation']\n",
    "    }\n",
    "    value_list = []\n",
    "    for datasets in df:\n",
    "        grouped_keys = key_map[(mean, inoc)]\n",
    "        grouped = datasets.groupby(grouped_keys, sort = False)\n",
    "        for name, group in grouped:\n",
    "            strain_name = group['Bacterial strain'].iloc[0]\n",
    "            media_comp = group['Medium composition'].iloc[0]\n",
    "            status = group['Status'].iloc[0]\n",
    "            if inoc == True:\n",
    "                inoculation = group['Inoculation'].iloc[0]\n",
    "            if mean == False:\n",
    "                well = group['Wells'].iloc[0]\n",
    "            values = group['Extinction OD620nm'].values\n",
    "            time = group['Time in h'].values\n",
    "            derivative = np.gradient(values)\n",
    "            positive_derivatives = derivative.copy()\n",
    "            positive_derivatives[positive_derivatives <= 0] = np.nan\n",
    "            mean_previous_derivatives = np.convolve(positive_derivatives, np.ones(window)/window, mode='valid')\n",
    "            significant_rise_indices = np.where(positive_derivatives[window-1:] > threshold * mean_previous_derivatives)[0] + window - 1\n",
    "            if significant_rise_indices.any():\n",
    "                rise_index = (significant_rise_indices[0] * 10 / 60)\n",
    "                #sns.lineplot(x = time, y = values)\n",
    "                #plt.axvline(x=int(round(rise_index)), color='r', linestyle='--')\n",
    "                #plt.show()\n",
    "                if mean == True and inoc == True:\n",
    "                    key = f\"{strain_name}_{media_comp}_{status}_{inoculation}\"\n",
    "                elif mean == True and inoc == False:\n",
    "                    key = f\"{strain_name}_{media_comp}_{status}\"\n",
    "                elif mean == False and inoc == True:\n",
    "                    key = f\"{strain_name}_{media_comp}_{status}_{well}_{inoculation}\"\n",
    "                else:\n",
    "                    key = f\"{strain_name}_{media_comp}_{status}_{well}\"\n",
    "                max_dict[key] = rise_index\n",
    "            else:\n",
    "                rise_index = 24\n",
    "                if mean == True and inoc == True:\n",
    "                    key = f\"{strain_name}_{media_comp}_{status}_{inoculation}\"\n",
    "                elif mean == True and inoc == False:\n",
    "                    key = f\"{strain_name}_{media_comp}_{status}\"\n",
    "                elif mean == False and inoc == True:\n",
    "                    key = f\"{strain_name}_{media_comp}_{status}_{well}_{inoculation}\"\n",
    "                else:\n",
    "                    key = f\"{strain_name}_{media_comp}_{status}_{well}\"\n",
    "                max_dict[key] = rise_index\n",
    "    for strain, value in max_dict.items():\n",
    "        value_list.append(value)\n",
    "    df_results['Onset delay time'] = value_list\n",
    "            \n",
    "onset_derivatives([deff_change_1, deff_change_2, deff_cahnge_3, deff_cahnge_4, deff_cahnge_5, deff_change_6, deff_change_7, deff_change_8, deff_change_9, deff_change_10], 7, 0.2, df_change, True, True)\n",
    "onset_derivatives([deff, deff_2, deff_3, deff_7, deff_8], 7, 0.2, df, True, False)\n",
    "onset_derivatives([G1,G2,G3,G7,G8], 7, 0.2, df_non_mean, False, False)\n",
    "onset_derivatives([Gc1,Gc2,Gc3,Gc4,Gc5,Gc6,Gc7,Gc8,Gc9,Gc10], 7, 0.2, df_change_non_mean, False, False)\n",
    "onset_derivatives([G24], 7, 0.2, df_24h, True, True)\n",
    "onset_derivatives([G24], 7, 0.2, df_24h_non_mean, False, True)\n",
    "onset_derivatives([pellets_1, pellets_2, pellets_3, pellets_4, pellets_5], 7, 0.2, df_pellets, True, False)\n",
    "onset_derivatives([fast_change_mi, fast_change_am, fast_change_lr, fast_change_fp, fast_change_ef, fast_change_ci, fast_change_ba, fast_change_bc, fast_change_ec, fast_change_au], 7, 0.2, df_fast, True, True)\n",
    "onset_derivatives([p_1, p_2, p_3, p_4, p_5], 7, 0.2, df_p, True, False)\n",
    "onset_derivatives([f_mi, f_am, f_lr, f_fp, f_ef, f_ci, f_ba, f_bc, f_ec, f_au], 7, 0.2, df_fast_non_mean, False, True)\n",
    "onset_derivatives([fm1, fm2, fm3, fm4, fm5], 7, 0.2, firmi_df, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ultimate_plots(df, growth_df):\n",
    "    hue_colors = {\n",
    "        'Standard AAM - Non-evolved': '#f0e594', \n",
    "        'Standard AAM - Evolved': '#57b884', \n",
    "        'AAM + HFD - Non-evolved': '#ffab8d', \n",
    "        'AAM + HFD - Evolved': '#f2cbac', \n",
    "        'AAM + CHOW - Non-evolved': '#ff6a9e', \n",
    "        'AAM + CHOW - Evolved': '#68baf9'\n",
    "    }\n",
    "\n",
    "    # Define the desired order for Media_Status\n",
    "    media_status_order = [\n",
    "        'Standard AAM - Non-evolved', \n",
    "        'Standard AAM - Evolved', \n",
    "        'AAM + HFD - Non-evolved', \n",
    "        'AAM + HFD - Evolved', \n",
    "        'AAM + CHOW - Non-evolved', \n",
    "        'AAM + CHOW - Evolved'\n",
    "    ]\n",
    "\n",
    "    growth_df = growth_df.rename(columns={'Bacterial strain': 'strain'})\n",
    "    strain_names = growth_df['strain'].unique()\n",
    "    \n",
    "    for strain in strain_names:\n",
    "        strain_data = df[df['strain'] == strain].copy()\n",
    "        strain_growth_data = growth_df[growth_df['strain'] == strain].copy()\n",
    "\n",
    "        # Create 'Media_Status' for both dataframes\n",
    "        strain_data['Media_Status'] = strain_data['Media composition'] + \" - \" + strain_data['Status']\n",
    "        strain_growth_data['Media_Status'] = strain_growth_data['Medium composition'] + \" - \" + strain_growth_data['Status']\n",
    "\n",
    "        # Ensure Media_Status follows the specified order\n",
    "        strain_data['Media_Status'] = pd.Categorical(strain_data['Media_Status'], categories=media_status_order, ordered=True)\n",
    "        strain_growth_data['Media_Status'] = pd.Categorical(strain_growth_data['Media_Status'], categories=media_status_order, ordered=True)\n",
    "        present_media_order = strain_data['Media_Status'].unique()\n",
    "        present_order = [status for status in media_status_order if status in present_media_order]\n",
    "\n",
    "        # Parameters to plot, ensuring they are numeric\n",
    "        parameters = [col for col in strain_data.columns if col not in ['strain', 'Media composition', 'Status', 'Media_Status'] and strain_data[col].dtype in [np.float64, np.int64]]\n",
    "\n",
    "        # Create figure and axes\n",
    "        num_params = len(parameters)\n",
    "        cols = max(1, num_params)  # Ensure at least one column\n",
    "        fig, axes = plt.subplots(1, cols + 1, figsize=(5 * cols + 5, 5))  # Plus one for the growth curve\n",
    "\n",
    "        # Bar plots for each parameter\n",
    "        for i, param in enumerate(parameters):\n",
    "            sns.barplot(x='Media_Status', y=param, hue='Media_Status', data=strain_data, ax=axes[i], dodge=False, palette=hue_colors, order=present_order, legend=False)\n",
    "            axes[i].set_title(f'{param} for {strain}')\n",
    "            axes[i].set_ylabel(param)\n",
    "            axes[i].tick_params(axis='x', rotation=90)\n",
    "\n",
    "        # Growth curve plot\n",
    "        axes[-1].set_title('Growth over Time for ' + strain)\n",
    "        axes[-1].set_xlabel('Time in hours')\n",
    "        axes[-1].set_ylabel('Extinction OD620nm')\n",
    "\n",
    "        # Plot each status with its respective color\n",
    "        for status in strain_growth_data['Media_Status'].unique():\n",
    "            subdata = strain_growth_data[strain_growth_data['Media_Status'] == status]\n",
    "            axes[-1].plot(subdata['Time in h'], subdata['Extinction OD620nm'], label=status, color=hue_colors[status])\n",
    "\n",
    "        axes[-1].legend(title='Media and Status', loc='upper left')\n",
    "        sns.move_legend(axes[-1], \"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perfect = pd.DataFrame(df_change_non_mean)\n",
    "#df_perfect = pd.concat([df_non_mean, df_change_non_mean], ignore_index= True)\n",
    "df_perfect_mean = pd.concat([df, df_change], ignore_index= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "#Sorting the df for the PCA\n",
    "\n",
    "df_full_change = pd.concat([df_change, df_fast])\n",
    "\n",
    "df_full_change = df_full_change.reset_index(drop=True)\n",
    "\n",
    "\n",
    "non_numerical_columns = df_full_change.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_columns = df_full_change.select_dtypes(exclude=['object']).columns.tolist()\n",
    "\n",
    "# Rearrange columns\n",
    "sorted_columns = non_numerical_columns + numerical_columns\n",
    "df_sorted = df_full_change[sorted_columns]\n",
    "\n",
    "#Scaling the df for thhe PCA\n",
    "\n",
    "df_encoded = pd.get_dummies(df_sorted, columns = ['strain', 'Media composition', 'Status'])\n",
    "\n",
    "features = ['slope', 'Max growth', 'AUC (Biomass)', 'Doubling time', 'Onset delay time']\n",
    "x = df_encoded[features].values\n",
    "x = StandardScaler().fit_transform(x)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principle_c = pca.fit_transform(x)\n",
    "principal_df = pd.DataFrame(data = principle_c, columns = ['principle component 1', 'principle component 2'])\n",
    "explained_variance_ratios = pca.explained_variance_ratio_\n",
    "print(explained_variance_ratios)\n",
    "final_df = pd.concat([principal_df, df_full_change[['strain', 'Status', 'Media composition']]], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = {'Evolved': 'o', 'Non-evolved': 's'}\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Scatter plot with color-coded strains and different markers\n",
    "for strain_status in final_df['Status'].unique():\n",
    "    subset = final_df[final_df['Status'] == strain_status]\n",
    "    plt.scatter(subset['principle component 1'], \n",
    "                subset['principle component 2'], \n",
    "                c=pd.Categorical(subset['strain']).codes, \n",
    "                cmap='viridis', \n",
    "                marker=markers[strain_status], \n",
    "                label=strain_status)\n",
    "\n",
    "# Add annotations\n",
    "for i, (pc1, pc2) in enumerate(zip(final_df['principle component 1'], final_df['principle component 2'])):\n",
    "    label = (final_df['strain'][i], final_df['Status'][i], final_df['Media composition'][i])\n",
    "    plt.annotate(label, (pc1, pc2), textcoords=\"offset points\", xytext=(5, 5), ha='right', fontsize=8)\n",
    "\n",
    "# Adding labels and title\n",
    "plt.title('PCA of Strain Data')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "\n",
    "# Adding a legend\n",
    "handles, labels = [], []\n",
    "for strain_status in final_df['Status'].unique():\n",
    "    handles.append(plt.Line2D([0], [0], marker=markers[strain_status], color='w', label=strain_status,\n",
    "                              markerfacecolor='k', markersize=10))\n",
    "    labels.append(strain_status)\n",
    "plt.legend(handles=handles, title=\"Status\")\n",
    "\n",
    "# Show plot\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca_by_media(media_composition):\n",
    "    df_filtered = final_df[final_df['Media composition'] == media_composition]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    scatter = plt.scatter(df_filtered['principle component 1'], \n",
    "                          df_filtered['principle component 2'], \n",
    "                          c=pd.Categorical(df_filtered['strain']).codes, \n",
    "                          cmap='viridis')\n",
    "    for i, (pc1, pc2) in enumerate(zip(df_filtered['principle component 1'], df_filtered['principle component 2'])):\n",
    "        label = f\"{df_filtered['strain'].iloc[i]}, {df_filtered['Status'].iloc[i]}\"\n",
    "        plt.annotate(label, (pc1, pc2), textcoords=\"offset points\", xytext=(5,5), ha='right', fontsize=8)\n",
    "    plt.title(f'PCA of Strain Data - {media_composition}')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.legend(handles=scatter.legend_elements()[0], labels=list(df_filtered['strain'].unique()), title=\"Strains\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Plot for each media composition\n",
    "media_compositions = final_df['Media composition'].unique()\n",
    "for media in media_compositions:\n",
    "    plot_pca_by_media(media)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Scatter plot with color-coded strains\n",
    "scatter = plt.scatter(final_df['principle component 1'], \n",
    "                      final_df['principle component 2'], \n",
    "                      c=pd.Categorical(final_df['strain']).codes, \n",
    "                      cmap='viridis', label=final_df['strain'])\n",
    "\n",
    "for i, (pc1, pc2) in enumerate(zip(final_df['principle component 1'], final_df['principle component 2'])):\n",
    "    label = (final_df['strain'][i], final_df['Status'][i], final_df['Media composition'][i])\n",
    "    plt.annotate(label, (pc1, pc2), textcoords=\"offset points\", xytext=(5,5), ha='right', fontsize=8)\n",
    "\n",
    "# Adding labels and title\n",
    "plt.title('PCA of Strain Data')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "\n",
    "# Adding a legend\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=list(final_df['strain'].unique()), title=\"Strains\")\n",
    "\n",
    "# Show plot\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_isolates = pd.DataFrame()\n",
    "feature_weights = {'slope': 1, 'Max growth': 2, 'AUC (Biomass)': 2, 'Doubling time': -.1, 'Onset delay time': -.1}\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_results_isolates[['slope', 'Max growth', 'AUC (Biomass)', 'Doubling time', 'Onset delay time']] = scaler.fit_transform(df_p[['slope', 'Max growth', 'AUC (Biomass)', 'Doubling time', 'Onset delay time']])\n",
    "\n",
    "df_results_isolates['Target'] = (df_p['slope'] * feature_weights['slope'] +\n",
    "                df_p['Max growth'] * feature_weights['Max growth'] +\n",
    "                df_p['AUC (Biomass)'] * feature_weights['AUC (Biomass)'] +\n",
    "                df_p['Doubling time'] * feature_weights['Doubling time'] +\n",
    "                df_p['Onset delay time'] * feature_weights['Onset delay time'])\n",
    "\n",
    "df_results_isolates['Normalized_Target'] = (df_results_isolates['Target'] - df_results_isolates['Target'].mean()) / df_results_isolates['Target'].std()\n",
    "\n",
    "\n",
    "test_list_gp = df_results_isolates['Normalized_Target'].values\n",
    "df_p['Normalized target'] = test_list_gp\n",
    "df_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heatmap_pellets = df_p[['strain', 'Media composition', 'Normalized target']]\n",
    "\n",
    "# Pivot the DataFrame to have 'strain' as rows, 'Media composition' as columns, and 'Growth score' as values\n",
    "# Use 'Status' as hue\n",
    "heatmap_data = df_heatmap_pellets.pivot_table(index='strain', columns=['Media composition'], values='Normalized target')\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "plt.title('Impact of Media Composition on Growth Score for different mice conditions')\n",
    "plt.xlabel('Media Composition')\n",
    "plt.ylabel('Strain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_isolates = pd.DataFrame()\n",
    "feature_weights = {'slope': 1, 'Max growth': 2, 'AUC (Biomass)': 2, 'Doubling time': -.1, 'Onset delay time': -.1}\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_results_isolates[['slope', 'Max growth', 'AUC (Biomass)', 'Doubling time', 'Onset delay time']] = scaler.fit_transform(firmi_df[['slope', 'Max growth', 'AUC (Biomass)', 'Doubling time', 'Onset delay time']])\n",
    "\n",
    "df_results_isolates['Target'] = (firmi_df['slope'] * feature_weights['slope'] +\n",
    "                firmi_df['Max growth'] * feature_weights['Max growth'] +\n",
    "                firmi_df['AUC (Biomass)'] * feature_weights['AUC (Biomass)'] +\n",
    "                firmi_df['Doubling time'] * feature_weights['Doubling time'] +\n",
    "                firmi_df['Onset delay time'] * feature_weights['Onset delay time'])\n",
    "\n",
    "df_results_isolates['Normalized_Target'] = (df_results_isolates['Target'] - df_results_isolates['Target'].mean()) / df_results_isolates['Target'].std()\n",
    "\n",
    "\n",
    "test_list_gp = df_results_isolates['Normalized_Target'].values\n",
    "firmi_df['Normalized target'] = test_list_gp\n",
    "firmi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heatmap_pellets = firmi_df[['strain', 'Media composition', 'Normalized target']]\n",
    "\n",
    "# Pivot the DataFrame to have 'strain' as rows, 'Media composition' as columns, and 'Growth score' as values\n",
    "# Use 'Status' as hue\n",
    "heatmap_data = df_heatmap_pellets.pivot_table(index='strain', columns=['Media composition'], values='Normalized target')\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "plt.title('Impact of Media Composition on Growth Score for different mice conditions')\n",
    "plt.xlabel('Media Composition')\n",
    "plt.ylabel('Strain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame()\n",
    "# Define feature weights (you can adjust these based on domain knowledge)\n",
    "feature_weights = {'slope': 1, 'Max growth': 1, 'AUC (Biomass)': 1, 'Doubling time': -.1, 'Onset delay time': -.1}\n",
    "\n",
    "# Normalize the features\n",
    "scaler = MinMaxScaler()\n",
    "df_results[['slope', 'Max growth', 'AUC (Biomass)', 'Doubling time', 'Onset delay time']] = scaler.fit_transform(df_perfect_mean[['slope', 'Max growth', 'AUC (Biomass)', 'Doubling time', 'Onset delay time']])\n",
    "\n",
    "# Calculate the composite target metric\n",
    "df_results['Target'] = (df_perfect_mean['slope'] * feature_weights['slope'] +\n",
    "                df_perfect_mean['Max growth'] * feature_weights['Max growth'] +\n",
    "                df_perfect_mean['AUC (Biomass)'] * feature_weights['AUC (Biomass)'] +\n",
    "                df_perfect_mean['Doubling time'] * feature_weights['Doubling time'] +\n",
    "                df_perfect_mean['Onset delay time'] * feature_weights['Onset delay time'])\n",
    "\n",
    "# Optionally, you can rescale the target metric to a desired range (e.g., 1 to 10)\n",
    "# Here's an example of rescaling to a range of 1 to 10\n",
    "#Z-score calculation:\n",
    "df_results['Normalized_Target'] = (df_results['Target'] - df_results['Target'].mean()) / df_results['Target'].std()\n",
    "\n",
    "\n",
    "test_list_gp = df_results['Normalized_Target'].values\n",
    "df_perfect_mean['Normalized target'] = test_list_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fast_results = pd.DataFrame()\n",
    "# Define feature weights (you can adjust these based on domain knowledge)\n",
    "feature_weights = {'slope': 1, 'Max growth': 1, 'AUC (Biomass)': 1, 'Doubling time': -.1, 'Onset delay time': -.1}\n",
    "\n",
    "# Normalize the features\n",
    "scaler = MinMaxScaler()\n",
    "df_fast_results[['slope', 'Max growth', 'AUC (Biomass)', 'Doubling time', 'Onset delay time']] = scaler.fit_transform(df_fast[\n",
    "    ['slope', 'Max growth', 'AUC (Biomass)', 'Doubling time', 'Onset delay time']])\n",
    "\n",
    "# Calculate the composite target metric\n",
    "df_fast_results['Target'] = (df_fast['slope'] * feature_weights['slope'] +\n",
    "                df_fast['Max growth'] * feature_weights['Max growth'] +\n",
    "                df_fast['AUC (Biomass)'] * feature_weights['AUC (Biomass)'] +\n",
    "                df_fast['Doubling time'] * feature_weights['Doubling time'] +\n",
    "                df_fast['Onset delay time'] * feature_weights['Onset delay time'])\n",
    "\n",
    "# Optionally, you can rescale the target metric to a desired range (e.g., 1 to 10)\n",
    "# Here's an example of rescaling to a range of 1 to 10\n",
    "#Z-score calculation:\n",
    "df_fast_results['Normalized_Target'] = (df_fast_results['Target'] - df_fast_results['Target'].mean()) / df_fast_results['Target'].std()\n",
    "\n",
    "\n",
    "test_list_gp = df_fast_results['Normalized_Target'].values\n",
    "df_fast['Normalized target'] = test_list_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perfect_mean = df_perfect_mean[df_fast.columns]\n",
    "\n",
    "# Concatenating the DataFrames\n",
    "combined_df = pd.concat([df_perfect_mean, df_fast], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heatmap = combined_df[['strain', 'Media composition', 'Normalized target', 'Status', 'Inoculation']]\n",
    "\n",
    "# Pivot the DataFrame to have 'strain' as rows, 'Media composition', 'Status', and 'Inoculation' as columns\n",
    "heatmap_data = df_heatmap.pivot_table(index='strain', columns=['Media composition', 'Status', 'Inoculation'], values='Normalized target')\n",
    "# Plot heatmap with hierarchical indexing\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=0.9)\n",
    "ax = sns.heatmap(heatmap_data, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5, cbar_kws={'label': 'Normalized Target'})\n",
    "\n",
    "# Adjust space for labels\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "\n",
    "# Customize x-axis labels to include brackets\n",
    "ax.set_xticklabels(\n",
    "    [f'{status}, {inoculation}' for (_, status, inoculation) in heatmap_data.columns],\n",
    "    rotation=90, ha='right'\n",
    ")\n",
    "\n",
    "# Add brackets for Media composition\n",
    "media_compositions = heatmap_data.columns.get_level_values(0)\n",
    "unique_media = media_compositions.unique()\n",
    "media_ticks = {media: [] for media in unique_media}\n",
    "\n",
    "for pos, media in enumerate(media_compositions):\n",
    "    media_ticks[media].append(pos)\n",
    "\n",
    "# Manually draw brackets and labels for media composition\n",
    "for media, positions in media_ticks.items():\n",
    "    start, end = positions[0], positions[-1]\n",
    "    # Draw a line below the text\n",
    "    ax.hlines(y=-0.55, xmin=start, xmax=end + 1, color='black', clip_on=False, linewidth=1.5, transform=ax.get_xaxis_transform())\n",
    "    # Draw vertical lines at the start and end\n",
    "    ax.vlines(x=start, ymin=-0.55, ymax=-0.5, color='black', clip_on=False, linewidth=1.5, transform=ax.get_xaxis_transform())\n",
    "    ax.vlines(x=end + 1, ymin=-0.55, ymax=-0.5, color='black', clip_on=False, linewidth=1.5, transform=ax.get_xaxis_transform())\n",
    "    # Add the label below the bracket\n",
    "    ax.text((start + end + 1) / 2, -0.6, media, ha='center', va='top', fontsize=10, weight='bold', rotation=0, transform=ax.get_xaxis_transform())\n",
    "\n",
    "plt.title('Impact of Media Composition on Growth Score for Each Strain (Status: Evolved/Non-evolved)')\n",
    "plt.xlabel('Media Composition, Status, Inoculation')\n",
    "plt.ylabel('Strain')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical analysis - Main module: Statsmodel api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mann_whitney_test(df):\n",
    "    p_val = {}\n",
    "    u_val = {}\n",
    "    parameters = ['slope', 'Max growth', 'AUC (Biomass)', 'Doubling time', 'Onset delay time']\n",
    "    grouped = df.groupby(['strain', 'Media composition'], sort=False)\n",
    "    for name, group in grouped:\n",
    "        p_values = {}\n",
    "        u_values = {}\n",
    "        medium = group['Media composition'].iloc[0]\n",
    "        strain = group['strain'].iloc[0]\n",
    "        \n",
    "        for parameter in parameters:\n",
    "            non_evolved = group[group['Status'] == 'Non-evolved'][parameter]\n",
    "            evolved = group[group['Status'] == 'Evolved'][parameter]\n",
    "            if len(evolved) > 0 and len(non_evolved) > 0:  # ensure there are data points to compare\n",
    "                u_stat, p_value = mannwhitneyu(non_evolved, evolved)\n",
    "                key = f\"{medium}_{parameter}\"\n",
    "                p_values[key] = p_value\n",
    "                u_values[key] = u_stat\n",
    "        if strain in p_val:\n",
    "            p_val[strain].append(p_values)\n",
    "            u_val[strain].append(u_values)\n",
    "        else:\n",
    "            p_val[strain] = [p_values]\n",
    "            u_val[strain] = [u_values]\n",
    "\n",
    "    return p_val, u_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val, u_val = mann_whitney_test(df_perfect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val_fast, u_val_fast = mann_whitney_test(df_fast_non_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ultimate_plots_p_value(df, growth_df, p_values):\n",
    "    hue_colors = {\n",
    "        'Standard AAM - Non-evolved': '#50e991', \n",
    "        'Standard AAM - Evolved': '#b3d4ff', \n",
    "        'AAM + HFD - Non-evolved': '#ffab8d', \n",
    "        'AAM + HFD - Evolved': '#bd7ebe', \n",
    "        'AAM + CHOW - Non-evolved': '#ff6a9e', \n",
    "        'AAM + CHOW - Evolved': '#fdcce5', \n",
    "        'Caecum medium - Non-evolved': '#68baf9' ,\n",
    "        'Caecum medium - Evolved': '#ffee65' \n",
    "    }\n",
    "\n",
    "    star_matrix = {\n",
    "        (0.05, float('inf')): '',\n",
    "        (0.01, 0.05): '*',\n",
    "        (0.001, 0.01): '**',\n",
    "        (0, 0.001): '***'\n",
    "    }\n",
    "\n",
    "    # Define the desired order for Media_Status\n",
    "    media_status_order = [\n",
    "            'Standard AAM - Non-evolved', \n",
    "            'Standard AAM - Evolved', \n",
    "            'AAM + HFD - Non-evolved', \n",
    "            'AAM + HFD - Evolved', \n",
    "            'AAM + CHOW - Non-evolved', \n",
    "            'AAM + CHOW - Evolved',\n",
    "            'Caecum medium - Non-evolved',\n",
    "            'Caecum medium - Evolved'\n",
    "        ]\n",
    "\n",
    "    growth_df = growth_df.rename(columns={'Bacterial strain': 'strain'})\n",
    "    strain_names = growth_df['strain'].unique()\n",
    "    \n",
    "    for strain in strain_names:\n",
    "        strain_data = df[df['strain'] == strain].copy()\n",
    "        strain_growth_data = growth_df[growth_df['strain'] == strain].copy()\n",
    "        \n",
    "        # Create 'Media_Status' for both dataframes\n",
    "        strain_data['Media_Status'] = strain_data['Media composition'] + \" - \" + strain_data['Status']\n",
    "        strain_growth_data['Media_Status'] = strain_growth_data['Medium composition'] + \" - \" + strain_growth_data['Status']\n",
    "        # Ensure Media_Status follows the specified order\n",
    "        strain_data['Media_Status'] = pd.Categorical(strain_data['Media_Status'], categories=media_status_order, ordered=True)\n",
    "        strain_growth_data['Media_Status'] = pd.Categorical(strain_growth_data['Media_Status'], categories=media_status_order, ordered=True)\n",
    "        present_media_order = strain_data['Media_Status'].unique()\n",
    "        present_order = [status for status in media_status_order if status in present_media_order]\n",
    "        \n",
    "        # Parameters to plot, ensuring they are numeric\n",
    "        parameters = [col for col in strain_data.columns if col not in ['strain', 'Media composition', 'Status', 'Media_Status'] and strain_data[col].dtype in [np.float64, np.int64]]\n",
    "\n",
    "        # Create figure and axes\n",
    "        num_params = len(parameters)\n",
    "        total_plots = num_params + 1  # One extra plot for the growth curve\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))  # 2 rows and 3 columns\n",
    "        \n",
    "        # Flatten the axes array for easier indexing\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        sns.set_style(\"white\")  # Set the background to white\n",
    "        \n",
    "        # Bar plots for each parameter\n",
    "        for i, param in enumerate(parameters):\n",
    "            sns.barplot(x='Media_Status', y=param, hue='Media_Status', data=strain_data, ax=axes[i], dodge=False, palette=hue_colors, order=present_order, legend=False)\n",
    "            sns.stripplot(x='Media_Status', y=param, data=strain_data, ax=axes[i], color='black', order=present_order, jitter=True, dodge=False, alpha=0.5)\n",
    "            axes[i].set_title(f'{param} for {strain}', y=1.1)\n",
    "            axes[i].set_ylabel(param)\n",
    "            axes[i].tick_params(axis='x', rotation=90)\n",
    "            axes[i].annotate(chr(65 + i), xy=(0.02, 0.98), xycoords='axes fraction', ha='left', va='top', fontsize=14, fontweight='bold')  # Add A, B, C, etc.\n",
    "            \n",
    "            for j in range(0, len(media_status_order), 2):  # Ensure it processes in pairs\n",
    "                x1_label = media_status_order[j]\n",
    "                x2_label = media_status_order[j + 1] if (j + 1) < len(media_status_order) else x1_label\n",
    "                medium, status = x1_label.split(' - ')\n",
    "                metric_key = f\"{medium}_{param}\"\n",
    "                if strain in p_values:\n",
    "                    for media_dict in p_values[strain]:\n",
    "                        if metric_key in media_dict:\n",
    "                            p_val = media_dict[metric_key]\n",
    "                            star = None\n",
    "                            for (lower_bound, upper_bound), stars in star_matrix.items():\n",
    "                                if lower_bound < p_val <= upper_bound:\n",
    "                                    star = stars\n",
    "                                    break  # Exit loop once the correct star is found\n",
    "                            if star:\n",
    "                                x1_pos = np.where(np.array(media_status_order) == x1_label)[0][0]\n",
    "                                x2_pos = np.where(np.array(media_status_order) == x2_label)[0][0]\n",
    "                                y = strain_data[param].max() * 1.05\n",
    "                                h = 0.05 * strain_data[param].max()\n",
    "\n",
    "                                # Draw the bracket\n",
    "                                bracket_height = y + h\n",
    "                                bracket_end_height = y + h * 0.8\n",
    "                                axes[i].plot([x1_pos, x1_pos, x2_pos, x2_pos], [y, bracket_height, bracket_height, y], lw=1.5, c='k')\n",
    "                                axes[i].annotate(star, xy=((x1_pos + x2_pos) / 2, bracket_height), xytext=(0, 5),\n",
    "                                                textcoords='offset points', ha='center', va='bottom', color='k')\n",
    "                            else:\n",
    "                                x1_pos = np.where(np.array(media_status_order) == x1_label)[0][0]\n",
    "                                x2_pos = np.where(np.array(media_status_order) == x2_label)[0][0]\n",
    "                                y = strain_data[param].max() * 1.05\n",
    "                                h = 0.05 * strain_data[param].max()\n",
    "\n",
    "                                # Draw the bracket\n",
    "                                bracket_height = y + h\n",
    "                                bracket_end_height = y + h * 0.8\n",
    "                                axes[i].plot([x1_pos, x1_pos, x2_pos, x2_pos], [y, bracket_height, bracket_height, y], lw=1.5, c='k')\n",
    "                                axes[i].annotate('ns', xy=((x1_pos + x2_pos) / 2, bracket_height), xytext=(0, 5),\n",
    "                                                textcoords='offset points', ha='center', va='bottom', color='k')\n",
    "        \n",
    "        # Line plot for growth over time\n",
    "        growth_ax = axes[num_params]\n",
    "        for status in strain_data['Media_Status'].unique():\n",
    "            subdata = strain_growth_data[strain_growth_data['Media_Status'] == status]\n",
    "            growth_ax.plot(subdata['Time in h'], subdata['Extinction OD620nm'], label=status, color=hue_colors[status])\n",
    "        \n",
    "        growth_ax.set_title('Growth over Time for ' + strain, y=1.1)\n",
    "        growth_ax.set_xlabel('Time in hours')\n",
    "        growth_ax.set_ylabel('Extinction OD620nm')\n",
    "        growth_ax.legend(title='Media and Status', bbox_to_anchor=(0.5, -0.3), loc= 'upper center', ncol = 1)\n",
    "        growth_ax.annotate(chr(65 + num_params), xy=(0.02, 0.98), xycoords='axes fraction', ha='left', va='top', fontsize=14, fontweight='bold')  # Add label to the growth plot\n",
    "\n",
    "        # Removing extra subplots\n",
    "        for i in range(total_plots, len(axes)):\n",
    "            fig.delaxes(axes[i])\n",
    "\n",
    "        sns.despine()\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ultimate_plots_p_value(df_perfect, deff_change_1, p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ultimate_plots_p_value(df_fast_non_mean, fast_change_mi, p_val_fast )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ultimate_plots_p_value(df_perfect, deff_change_2, p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ultimate_plots_p_value(df_fast_non_mean, fast_change_ec, p_val_fast )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ultimate_plots_p_value(df_perfect, deff_cahnge_3, p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ultimate_plots_p_value(df_fast_non_mean, fast_change_ef, p_val_fast )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ultimate_plots_p_value(df_perfect, deff_cahnge_4, p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ultimate_plots_p_value(df_fast_non_mean, fast_change_ci, p_val_fast )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ultimate_plots_p_value(df_perfect, deff_cahnge_5, p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ultimate_plots_p_value(df_fast_non_mean, fast_change_fp, p_val_fast )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ultimate_plots_p_value(df_perfect, deff_change_6, p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ultimate_plots_p_value(df_fast_non_mean, fast_change_am, p_val_fast )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ultimate_plots_p_value(df_perfect, deff_change_7, p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ultimate_plots_p_value(df_fast_non_mean, fast_change_bc, p_val_fast )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ultimate_plots_p_value(df_perfect, deff_change_8, p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ultimate_plots_p_value(df_fast_non_mean, fast_change_au, p_val_fast )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ultimate_plots_p_value(df_perfect, deff_change_9, p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ultimate_plots_p_value(df_fast_non_mean, fast_change_ba, p_val_fast )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ultimate_plots_p_value(df_perfect, deff_change_10, p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ultimate_plots_p_value(df_fast_non_mean, fast_change_lr, p_val_fast )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
